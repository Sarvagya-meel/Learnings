{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81456dd",
   "metadata": {},
   "source": [
    "# Lesson 1: Multi-Agent Conversation and Stand-up Comedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4693467e",
   "metadata": {},
   "source": [
    "Welcome to Lesson 1.\n",
    "\n",
    "To access the `requirements.txt` file and the`utils` modules, please go to the `File` menu and select`Open...`.\n",
    "\n",
    "I hope you enjoy this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742cf649",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d006c1-22fa-40ea-b3e0-d543142e0788",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Example: Access an environment variable\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8646c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"model\": \"gpt-3.5-turbo\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a1c4d",
   "metadata": {},
   "source": [
    "## Define an AutoGen agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb8c441-c58c-41a8-a54b-5c387afceac5",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogen in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (0.9)\n",
      "Requirement already satisfied: pyautogen==0.9 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from autogen) (0.9.0)\n",
      "Requirement already satisfied: anyio<5.0.0,>=3.0.0 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from pyautogen==0.9->autogen) (4.9.0)\n",
      "Requirement already satisfied: asyncer==0.0.8 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from pyautogen==0.9->autogen) (0.0.8)\n",
      "Requirement already satisfied: diskcache in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from pyautogen==0.9->autogen) (5.6.3)\n",
      "Requirement already satisfied: docker in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from pyautogen==0.9->autogen) (7.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.28.1 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from pyautogen==0.9->autogen) (0.28.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from pyautogen==0.9->autogen) (25.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6.1 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from pyautogen==0.9->autogen) (2.11.4)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from pyautogen==0.9->autogen) (1.1.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from pyautogen==0.9->autogen) (3.1.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from pyautogen==0.9->autogen) (0.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from anyio<5.0.0,>=3.0.0->pyautogen==0.9->autogen) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from anyio<5.0.0,>=3.0.0->pyautogen==0.9->autogen) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from httpx<1,>=0.28.1->pyautogen==0.9->autogen) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from httpx<1,>=0.28.1->pyautogen==0.9->autogen) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.28.1->pyautogen==0.9->autogen) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from pydantic<3,>=2.6.1->pyautogen==0.9->autogen) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from pydantic<3,>=2.6.1->pyautogen==0.9->autogen) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from pydantic<3,>=2.6.1->pyautogen==0.9->autogen) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from pydantic<3,>=2.6.1->pyautogen==0.9->autogen) (0.4.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from docker->pyautogen==0.9->autogen) (310)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from docker->pyautogen==0.9->autogen) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from docker->pyautogen==0.9->autogen) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from requests>=2.26.0->docker->pyautogen==0.9->autogen) (3.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\sarva\\onedrive\\documents\\projectspace\\learnings\\.venv\\lib\\site-packages (from tiktoken->pyautogen==0.9->autogen) (2024.11.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "A module needed for autogen.oai.client.create_openai_client is missing:\n - 'openai' is not installed.\nPlease install it using:\n'pip install ag2[openai]'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mpip\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minstall autogen\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogen\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConversableAgent\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m agent = \u001b[43mConversableAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchatbot\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhuman_input_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNEVER\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sarva\\OneDrive\\Documents\\ProjectSpace\\Learnings\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:261\u001b[39m, in \u001b[36mConversableAgent.__init__\u001b[39m\u001b[34m(self, name, system_message, is_termination_msg, max_consecutive_auto_reply, human_input_mode, function_map, code_execution_config, llm_config, default_auto_reply, description, chat_messages, silent, context_variables, functions, update_agent_state_before_reply, handoffs)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    256\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPlease implement __deepcopy__ method for each value class in llm_config to support deepcopy.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Refer to the docs for more details: https://docs.ag2.ai/docs/user-guide/advanced-concepts/llm-configuration-deep-dive/#adding-http-client-in-llm_config-for-proxy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28mself\u001b[39m.llm_config = \u001b[38;5;28mself\u001b[39m._validate_llm_config(llm_config)\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_client\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_name(name)\n\u001b[32m    263\u001b[39m \u001b[38;5;28mself\u001b[39m._name = name\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sarva\\OneDrive\\Documents\\ProjectSpace\\Learnings\\.venv\\Lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:505\u001b[39m, in \u001b[36mConversableAgent._create_client\u001b[39m\u001b[34m(cls, llm_config)\u001b[39m\n\u001b[32m    503\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_client\u001b[39m(\u001b[38;5;28mcls\u001b[39m, llm_config: Union[LLMConfig, Literal[\u001b[38;5;28;01mFalse\u001b[39;00m]]) -> Optional[OpenAIWrapper]:\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m llm_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mOpenAIWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mllm_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sarva\\OneDrive\\Documents\\ProjectSpace\\Learnings\\.venv\\Lib\\site-packages\\autogen\\oai\\client.py:800\u001b[39m, in \u001b[36mOpenAIWrapper.__init__\u001b[39m\u001b[34m(self, config_list, **base_config)\u001b[39m\n\u001b[32m    798\u001b[39m     config_list = [config.copy() \u001b[38;5;28;01mfor\u001b[39;00m config \u001b[38;5;129;01min\u001b[39;00m config_list]  \u001b[38;5;66;03m# make a copy before modifying\u001b[39;00m\n\u001b[32m    799\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m config \u001b[38;5;129;01min\u001b[39;00m config_list:\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_register_default_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenai_config\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# could modify the config\u001b[39;00m\n\u001b[32m    801\u001b[39m         \u001b[38;5;28mself\u001b[39m._config_list.append({\n\u001b[32m    802\u001b[39m             **extra_kwargs,\n\u001b[32m    803\u001b[39m             **{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.openai_kwargs},\n\u001b[32m    804\u001b[39m         })\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sarva\\OneDrive\\Documents\\ProjectSpace\\Learnings\\.venv\\Lib\\site-packages\\autogen\\oai\\client.py:944\u001b[39m, in \u001b[36mOpenAIWrapper._register_default_client\u001b[39m\u001b[34m(self, config, openai_config)\u001b[39m\n\u001b[32m    941\u001b[39m         \u001b[38;5;28mself\u001b[39m._clients.append(OpenAIClient(client, response_format))\n\u001b[32m    942\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m client\n\u001b[32m--> \u001b[39m\u001b[32m944\u001b[39m     client = \u001b[43mcreate_openai_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled():\n\u001b[32m    947\u001b[39m     log_new_client(client, \u001b[38;5;28mself\u001b[39m, openai_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sarva\\OneDrive\\Documents\\ProjectSpace\\Learnings\\.venv\\Lib\\site-packages\\autogen\\import_utils.py:283\u001b[39m, in \u001b[36mPatchCallable.patch.<locals>._call\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m.msg)\n",
      "\u001b[31mImportError\u001b[39m: A module needed for autogen.oai.client.create_openai_client is missing:\n - 'openai' is not installed.\nPlease install it using:\n'pip install ag2[openai]'"
     ]
    }
   ],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    name=\"chatbot\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47886b5f-fc7c-431a-8036-cff6e88f85c6",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f626e9-4cec-40c1-abde-2eff1252b848",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Repeat the joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c98a301",
   "metadata": {},
   "source": [
    "## Conversation\n",
    "\n",
    "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f109dcb-824e-40d7-8e86-efee42b75f3c",
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f71a61",
   "metadata": {},
   "source": [
    "**Note**: You might get a slightly different response (set of jokes) than what is shown in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a1c6f6-687e-40de-8819-374201cfed9f",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edc810",
   "metadata": {},
   "source": [
    "## Print some results\n",
    "\n",
    "You can print out:\n",
    "\n",
    "1. Chat history\n",
    "2. Cost\n",
    "3. Summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169ea24-eadd-4909-8d56-9b7ec5677c66",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550267b6-3652-40dc-9997-c5401f6d4c47",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf468e-d217-4731-8cb4-3485377230f1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c6cf8",
   "metadata": {},
   "source": [
    "## Get a better summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a8fef1-8030-4652-a2d2-1648834f62c2",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\", \n",
    "    max_turns=2, \n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b042de62-bc49-49ee-99f2-4f972e23670b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300525bd",
   "metadata": {},
   "source": [
    "## Chat Termination\n",
    "\n",
    "Chat can be terminated using a termination conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044dfd61-7f1d-46d8-9e28-4b2601b43d70",
   "metadata": {
    "height": 351
   },
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49d959-1025-4709-8866-9d4035eaeae7",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846eccbd-efd1-464b-9385-279c19b17c1d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
